---
sidebar_position: 2
---


# Improving the model

To improve the model from a simple `Decisiontreeclassifier`, we opted for a solution with a `Randomforrestclassifier` which is basicly just multiple `Decisiontreeclassifiers`, where each of them has a vote and then the majority wins for a specific classification. 

With the basic `Randomforrestclassifier`we obtained far better results.

[ ![](confusionMatrix_RF.png) ](confusionMatrix_RF.png)

Comparing the two *Confusion matrices* the true postives has gone from 59 to 104, likewise the false positive has been increased from 17 to 39. 
As for the true negatives it reduced by from 43 to 21, however that is the cost of having correctly classified far more. 
Likewise the False negative was reduced from 53 to 8! This overall gives us a better model.

With the different results from the confusion matrix we now obtained the following: 

*  Accuracy of the model: 0.7267441860465116
* Precision of the model: 0.7272727272727273
* recall of the model: 0.9285714285714286

With an increase in every aspect except for a little worse precision, we are actually happy. 
Ofcourse it is better to get it right more times whether or not a county is obesed. But likewise with an increased recall we ensure that we get the most counties that can be considered obesed based on features, and thus are able to account for based on said features to improve public health in that county! 

### Further improving the model

The `Randomforrestclassifier` uses different *Hyperparameters* that can be tuned in order to improve the overall accuracy of the model. 
By performing `RandomSearchCV`to first establish how the hyperparameters act on the model and then `GridSearchCV`to find different parameters for the said model in an interval we were able to further improve the model accuracy. 
With the new *hyperparameters* we arrive with the following confusion matrix and measurements

[ ![](confusionMatrix_RF_tuned.png) ](confusionMatrix_RF_tuned.png)

* Accuracy of the model: 0.7325581395348837
* Precision of the model: 0.7171052631578947
* recall of the model: 0.9732142857142857

Based upon the measurements above we arrive with a model with less `Precison`. However an increase in the `Accuray` and `Recall`.

Based on that and the confusion matrix numbers we see a model that identifies more true positives, but at the cost of more false positives and thus the increased `Recall`. Likewise we see a minor decrease in true negatives, but a reduction in false negaitves. As this doesn't classify whether one individual has a disease or is life critical for one individual, but rather identifies whether or not a county is more vulnerable of obesity or not it is a good thing to identify to many to try to prohibit this prediction. 

Below can be seen the importance of the different features

[ ![](Feature_imps.png) ](Feature_imps.png)

As seen, the most important feature seem to be `smoking` percentagesðŸš¬ in the county which has around 40% of the importance. The next is `Years_of_Potential_Life_Lost_Rate` however with a large standard deviation. Therafter is `percentage republican` which seems to also have a positive affect, however with an even larger standard deviation. Furthermore, as mentioned in the motivation, stress and other types of mentally unhealth could affect obesity, which turned out to be the third most important feature.

The model then predicts obesity in a county if these features are prevalent. It can of course be discussed that it is unclear if smoking is a precondition to being obese or if it is actually the other way around, which counts for all of the features, this would need to be investigated further to conclude uponðŸ”Ž.